\section{Introducción Teórica}

\subsection{Page Rank}

La manera en cómo se modela el problema del ranking es usando una matriz de adyacencias. Sea $W \in \mathbb{R}^{n \times n}$ donde $n$ es la cantidad de sitios indexados, luego el elemento $w_{ij}$ es igual $1$ si existe un link de la página $i$ a la página $j$ y $0$ en caso contrario. A su vez los links autoreferenciados se ignoran por lo que en diagonal tenemos todos valores nulos.\\

Ahora con $W$ podemos extraer la cantidad de links salientes de cada página, simplemente sumando los elementos de la fila correspondiente, llamemos $n_j$ al grado de la página $j$ donde $n_j = \sum^{n}_{i = 1} w_{ij}$

\subsection{QR y Reflecciones de Householder}

Existen variadas formas de descomponer una matriz, en este trabajo en particular usaremos $QR$, el cual consiste en descomponer una matriz $A$ en una matriz ortogonal $Q$ y una triangular superior $R$ de manera que $A = QR$. Al tener descompuesta $A$ en esa forma y teniendo un sistema $Ax = b$, la obtención del vector solución se realiza resolviendo el sistema $Rx = Q^{t}b$.\\

A su vez existen distintos procedimientos para poder hallar la descomposición $QR$ de una matriz, una de ellas son las Reflecciones de Householder, las cuales consisten en ir poniendo ceros debajo de la diagonal en cada caso del procedimiento. Este procedimiento sólo se puede llevar a cabo si es que la matriz tiene mas filas que columnas o a la sumo igual cantidad.\\

Yendo en detalle: Sea $A \in \mathbb{R}^{m \times n}$ una matriz con $m \ge n$, sea $x$ el vector columna correspondiente a la primer columna



\subsection{Cálculo alternativo de $x^{(k + 1)} = P_2x^{(k)}$}

Veamos primero cómo utilizando el algoritmo de Kamvar podemos optimizar el espacio requerido en memoria para el almacenamiento de la matriz $P_2$ y el tiempo de ejecución requerido para hacer la multiplicación entre matrices y vectores.\\

\newcommand{\vectornorm}[1]{\left\|#1\right\|}
Queremos ver que el algoritmo propuesto por \cite[Algoritmo 1]{Kamvar2003} es equivalente
a la operación $\vec{y} = A\vec{x}$, para $A=(cP' + (1-c)E)^{t}$, donde $P'$ es la matriz 
estocástica por filas de transiciones de links ajustada para considerar saltos aleatorios
en páginas sin outlinks, y $E$ es la matriz uniforme de teletransportación con valor $\frac{1}{n}$ en cada celda.

Para ello, expandimos las ecuaciones de ambos y veremos que las mismas producen el mismo cálculo.

Primero, la matrix $P^{t}$ se desarrolla como 
\begin{align*}
(cP + (1 - c)E)^{t} \vec{x}
\end{align*}

Y la matrix de \cite[Algoritmo 1]{Kamvar 2003} como
\begin{align*}
cP^{t}\vec{x} + (\vectornorm{\vec{x}}_1 - \vectornorm{\vec{y}}_2)\vec{v}
\end{align*}

donde $\vec{y}$ es el vector resultante de $cP^{t}\vec{x}$ y $\vec{v}$ es el vector de probabilidad
uniforme de valor $\frac{1}{n}$ en cada elemento. Luego planteamos la equivalencia

\begin{align*}
(cP + (1-c)E)^{t} \vec{x} v&= cP^{t}\vec{x} + (\vectornorm{\vec{x}}_1 - \vectornorm{\vec{y}}_2)\vec{v} \\
cP^{t}\vec{x} + (1-c)E^{t}\vec{x} &= cP^{t}\vec{x} + (\vectornorm{\vec{x}}_1 - \vectornorm{\vec{y}}_2)\vec{v} \\
(1-c)E^{t}\vec{x} &= (\vectornorm{\vec{x}}_1 - \vectornorm{\vec{y}}_2)\vec{v}
\end{align*}

\subsection{Lema: $P^{t} \vec{x}$ preserva la Norma 1 de $\vec{x}$}
Sea $P^{t}$ una matriz estocástica por columnas, luego los elementos de cada columna suman 1.

Luego $P^{t}$ describe una transformación lineal de $\vec{x}$ donde la suma de los valores de cada $x_i$
se reparte en los $y_i$ resultantes (por ser cada $y_i$ una combinación lineal de los $x_i$.) 
Como cada columna de $P$ suma $1$, y cada elemento de $x$  se termina
multiplicando por los elementos de una columna, y además los valores de $P$ y $ x$  son positivos,
entonces la ecuación
\begin{align*}
\sum_{i=1}^{n} |x_i| \\
\end{align*}
\centerline{es equivalente a}
\begin{align*}
\sum_{i=1}^{n} |y_i|
\end{align*}
Luego $P^{t}$ preserva norma 1.

Volviendo al problema, si observamos que la norma 1 de $y$  es
\begin{align*}
\vectornorm{\vec{y}}_1 &= \vectornorm{cP^{t} \vec{x}}_1 \\
               &= c\vectornorm{\vec{x}}_1
\end{align*}
entonces podemos ver que

\begin{align*}
\vectornorm{\vec{x}}_1 - \vectornorm{\vec{y}}_1 &= \vectornorm{\vec{x}}_1 - c \vectornorm{\vec{x}}_1 \\
                                        &= (1-c) \vectornorm{\vec{x}}_1 \\
                                        &= (1-c) \vectornorm{\vec{x}}_1
\end{align*}

por ende
\begin{align*}
(\vectornorm{\vec{x}}_1 - \vectornorm{\vec{y}}_1)\vec{v} &= (1-c) \vectornorm{\vec{x}}_1 \vec{v}
\end{align*}

entonces el método de algortimo 1 tiene la forma
\begin{align*}
cP^{t}\vec{x} + (1-c) \vectornorm{\vec{x}}_1 \vec{v}
\end{align*}

Si observamos la segunda mitad de la definición de $P^{t}$, es decir, $(1-c)E^{t}$, veremos que el producto
a la izquierda por $\vec{x}$ resulta en una matrix con la forma

\begin{align*}
E^{t}\vec{x} &= 
\begin{bmatrix}
\frac{1-c}{n} \sum_{i=1}^{n} |x_{i}|  \\
\cdots  \\
\cdots  \\
\cdots  \\
\cdots  \\
\frac{1-c}{n} \sum_{i=1}^{n} |x_{i}|  \\
\end{bmatrix}
=
\begin{bmatrix}
\frac{1-c}{n} \vectornorm{\vec{x}}_1 \\
\cdots  \\
\cdots  \\
\cdots  \\
\cdots  \\
\frac{1-c}{n} \vectornorm{\vec{x}}_1 \\
\end{bmatrix}
=
(1-c)\frac{1}{n} \vectornorm{\vec{x}}_1
\end{align*}

Con ello concluimos que los dos términos del algoritmo de Kamvar son equivalentes
a la matriz $A$ de transiciones. $ \blacksquare $

